{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Json file creation from csv**"
      ],
      "metadata": {
        "id": "lHBZy24K6sqA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-Hru_R-Pwwl",
        "outputId": "3a9b39cc-c718-4235-c4e1-ab844b1d3d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion complete. JSONL file saved as fine.jsonl\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import json\n",
        "\n",
        "def csv_to_jsonl(input_csv, output_jsonl):\n",
        "    system_message = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"You are a fashion designer who helps to identify products, descriptions, and categories that should be served for user.\n",
        "\n",
        "Instructions:\n",
        "1. Identify all the products or series of products to serve best to the user is referring.\n",
        "2. For each identified product:\n",
        "    a. If the user provides enough details to describe the product, summarise those details as the \"description\".\n",
        "    b. If the user does not provide enough details, use the product name itself as the \"description\".\n",
        "4. Classify each product into one of the following categories:\n",
        "    ['men_clothing', 'women_clothing', 'men_watches', 'women_watches', 'men_shoes', 'women_shoes']\n",
        "\n",
        "CONSTRAINTS:\n",
        "\n",
        "ALL THE PRODUCTS SHOULD BE FROM SAME GENDER [MEN/WOMEN]. DONT MIX THEM\n",
        "\n",
        "Output:\n",
        "\n",
        "A JSON object with a list of product objects, each containing \"name\", \"description\", and \"category\" keys.\n",
        "\n",
        "Format and example:\n",
        "{\n",
        "    \"products\": [\n",
        "        {\n",
        "            \"name\": \"blue jeans\",\n",
        "            \"description\": \"blue denim jeans\",\n",
        "            \"category\": \"men_clothing\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"white shirts\",\n",
        "            \"description\": \"white shirts\",\n",
        "            \"category\": \"women_clothing\"\n",
        "        }\n",
        "    ]\n",
        "}\"\"\"\n",
        "    }\n",
        "\n",
        "    with open(input_csv, 'r', newline='', encoding='utf-8') as csvfile, open(output_jsonl, 'w', encoding='utf-8') as jsonlfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            entry = {\n",
        "                \"messages\": [\n",
        "                    system_message,\n",
        "                    {\"role\": \"user\", \"content\": row['query']},\n",
        "                    {\"role\": \"assistant\", \"content\": row['response']}\n",
        "                ]\n",
        "            }\n",
        "            jsonlfile.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "    print(f\"Conversion complete. JSONL file saved as {output_jsonl}\")\n",
        "\n",
        "# Usage\n",
        "input_csv = 'fine.csv'  # Replace with your CSV file name\n",
        "output_jsonl = 'fine.jsonl'  # Replace with desired output file name\n",
        "\n",
        "csv_to_jsonl(input_csv, output_jsonl)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Completing Format checks"
      ],
      "metadata": {
        "id": "oIekU_HZ60kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tiktoken  # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# Data loading\n",
        "data_path = \"fine.jsonl\"\n",
        "\n",
        "# Load the dataset\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNFUlxQLQL4z",
        "outputId": "9cda813d-91e6-418d-f852-0145f8eb0235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples: 107\n",
            "First example:\n",
            "{'role': 'system', 'content': 'You are a fashion designer who helps to identify products, descriptions, and categories that should be served for user.\\n\\nInstructions:\\n1. Identify all the products or series of products to serve best to the user is referring.\\n2. For each identified product:\\n    a. If the user provides enough details to describe the product, summarise those details as the \"description\".\\n    b. If the user does not provide enough details, use the product name itself as the \"description\".\\n4. Classify each product into one of the following categories:\\n    [\\'men_clothing\\', \\'women_clothing\\', \\'men_watches\\', \\'women_watches\\', \\'men_shoes\\', \\'women_shoes\\']\\n\\nCONSTRAINTS:\\n\\nALL THE PRODUCTS SHOULD BE FROM SAME GENDER [MEN/WOMEN]. DONT MIX THEM\\n\\nOutput:\\n\\nA JSON object with a list of product objects, each containing \"name\", \"description\", and \"category\" keys.\\n\\nFormat and example:\\n{\\n    \"products\": [\\n        {\\n            \"name\": \"blue jeans\",\\n            \"description\": \"blue denim jeans\",\\n            \"category\": \"men_clothing\"\\n        },\\n        {\\n            \"name\": \"white shirts\",\\n            \"description\": \"white shirts\",\\n            \"category\": \"women_clothing\"\\n        }\\n    ]\\n}'}\n",
            "{'role': 'user', 'content': 'Users gender is male. I need some casual wear for the weekend.'}\n",
            "{'role': 'assistant', 'content': '{ \"products\": [ { \"name\": \"Relaxed fit jeans\", \"description\": \"Comfortable denim jeans for casual wear\", \"category\": \"men_clothing\" }, { \"name\": \"Cotton polo shirt\", \"description\": \"Breathable polo shirt for weekend outings\", \"category\": \"men_clothing\" }, { \"name\": \"Chino shorts\", \"description\": \"Versatile khaki shorts for warm days\", \"category\": \"men_clothing\" } ] }'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if messages is None:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "    else:\n",
        "        for message in messages:\n",
        "            if \"role\" not in message or \"content\" not in message:\n",
        "                format_errors[\"message_missing_key\"] += 1\n",
        "            if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
        "                format_errors[\"message_unrecognized_key\"] += 1\n",
        "            if message.get(\"role\") not in (\"system\", \"user\", \"assistant\"):\n",
        "                format_errors[\"unrecognized_role\"] += 1\n",
        "            if not isinstance(message.get(\"content\", ''), str):\n",
        "                format_errors[\"missing_content\"] += 1\n",
        "        if not any(message.get(\"role\") == \"assistant\" for message in messages):\n",
        "            format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE0sDQykQx42",
        "outputId": "45497c19-c449-4c0a-e41f-99111ad5b9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "def num_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += len(encoding.encode(message['content']))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.05)}, {np.quantile(values, 0.95)}\")"
      ],
      "metadata": {
        "id": "BvEfaZ7XQ2LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    system_present = any(m[\"role\"] == \"system\" for m in messages)\n",
        "    user_present = any(m[\"role\"] == \"user\" for m in messages)\n",
        "    n_missing_system += not system_present\n",
        "    n_missing_user += not user_present\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_tokens_from_messages([m for m in messages if m[\"role\"] == \"assistant\"]))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0TLDPpuQ7p9",
        "outputId": "1ab2b44c-3de0-42f4-b0a7-a52d1507d1ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 331, 402\n",
            "mean / median: 388.85046728971963, 389.0\n",
            "p5 / p95: 382.3, 400.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 51, 120\n",
            "mean / median: 108.08411214953271, 108.0\n",
            "p5 / p95: 102.0, 117.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume each example's token count does not exceed the maximum context length for the model.\n",
        "n_epochs = 3  # typically a good starting point\n",
        "n_train_examples = len(dataset)\n",
        "n_billing_tokens_in_dataset = sum(min(402, l) for l in convo_lens)\n",
        "\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
        "\n",
        "# Visit OpenAI's pricing page for detailed cost information."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Kskxl-uRB6C",
        "outputId": "d71f8273-1425-403d-b0a0-37ac488598c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has ~41607 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~124821 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create file and Fine tuning Job"
      ],
      "metadata": {
        "id": "w6__W2NI6_lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key='XXX')\n",
        "\n",
        "response = client.files.create(\n",
        "    file=open(\"fine.jsonl\", \"rb\"),  # Make sure the file path and name are correct\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "print(response)  # This will print the response from the server including the file ID"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A-Ox3A-RUwF",
        "outputId": "e376fe80-601d-4a19-874c-0be40202b8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FileObject(id='file-OX399P52cYXvQhjXauzBww3S', bytes=201053, created_at=1723091836, filename='fine.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Start a fine-tuning job\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=\"file-OX399P52cYXvQhjXauzBww3S\",\n",
        "    model=\"gpt-3.5-turbo-0125\"  # Model type to fine-tune\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah89taU0SShZ",
        "outputId": "57972b44-6849-4c4a-f588-7f8a1dfa9683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FineTuningJob(id='ftjob-GLLP17wOXH7QpU8tKWKmBtLp', created_at=1723092776, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-5WlOT3q0QKbAJX4vVQIW85tY', result_files=[], seed=1428391678, status='validating_files', trained_tokens=None, training_file='file-OX399P52cYXvQhjXauzBww3S', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"ft:gpt-3.5-turbo-0125:personal::9tpkCK91\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "    ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDcCm5o2ZaoY",
        "outputId": "ae97222b-43f7-441d-dce4-16daa72cef35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    }
  ]
}